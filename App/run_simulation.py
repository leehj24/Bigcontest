# App/run_simulation.py
# - Streamlit self-bootstrap
# - DiscreteCQL(v2) ì²´í¬í¬ì¸íŠ¸ ë¡œë”: ê³ ì • í´ë”(Model/d3rlpy_logs/DiscreteCQL/) ìš°ì„ 
#   * params.json â†’ DiscreteCQLConfig.from_json â†’ cfg.create(device) â†’ ë”ë¯¸ Datasetìœ¼ë¡œ build â†’ .d3 ë¡œë“œ
#   * 100KB ì´í•˜ .d3ëŠ” ìë™ ìŠ¤í‚µ
#   * ê³ ì • í´ë”ê°€ ë¹„ë©´ logs_root ì „ì²´ë¥¼ í›„ìˆœìœ„ë¡œ ìŠ¤ìº”
# - PyTorch 2.6+ í˜¸í™˜: d3rlpy ë‚´ë¶€ torch.load(weights_only=True) íšŒí”¼ íŒ¨ì¹˜
# - í˜„ì¬ ì•±ì€ ë¬´ìŠ¤ì¼€ì¼ ì¶”ë¡ (ì›ê°’). í•„ìš” ì‹œ ìŠ¤ì¼€ì¼ëŸ¬ ì ìš© ì½”ë“œì˜ TODO ì£¼ì„ ì°¸ê³ 

import os, sys, subprocess, random
from pathlib import Path
import json
import warnings

# ------------------------------------------------------------
# Self-bootstrap: pythonìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰í•˜ë©´ streamlit runìœ¼ë¡œ ì¬ì‹¤í–‰
# ------------------------------------------------------------
if __name__ == "__main__" and os.environ.get("STREAMLIT_BOOTSTRAPPED") != "1":
    file_path = str(Path(__file__).resolve())
    env = os.environ.copy()
    env["STREAMLIT_BOOTSTRAPPED"] = "1"
    cmd = [sys.executable, "-m", "streamlit", "run", file_path]
    subprocess.run(cmd, env=env, check=False)
    sys.exit(0)

# ------------------------------------------------------------
# App ë³¸ì²´
# ------------------------------------------------------------
import streamlit as st
import pandas as pd
import numpy as np
import torch

from d3rlpy.algos import DiscreteCQLConfig
from d3rlpy.dataset import MDPDataset

# Gym ê²½ê³ ê°€ ê±°ìŠ¬ë¦¬ë©´ ì–µì œ(í™˜ê²½ì„ ì“°ì§€ ì•Šìœ¼ë¯€ë¡œ ì•ˆì „)
warnings.filterwarnings("ignore", message="Gym has been unmaintained since 2022")

# --- PyTorch 2.6+ í˜¸í™˜: d3rlpy ë‚´ë¶€ torch.load(weights_only=True) íšŒí”¼ ---
import torch as _torch
_torch_load_orig = _torch.load
def _torch_load_compat(*args, **kwargs):
    kwargs["weights_only"] = False  # ê°•ì œ
    return _torch_load_orig(*args, **kwargs)
_torch.load = _torch_load_compat
# ---------------------------------------------------------------------------

LATENT_DIM = 16
FEATURES = [
    'DLV_SAA_RAT',          # ë°°ë‹¬ ë§¤ì¶œ ë¹„ì¤‘(%)
    'MCT_UE_CLN_REU_RAT',   # ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨(%)
    'MCT_UE_CLN_NEW_RAT',   # ì‹ ê·œ ê³ ê° ë¹„ìœ¨(%)
    'RC_M1_SAA_RANK',       # ë§¤ì¶œ ìˆœìœ„ êµ¬ê°„(1=ìƒìœ„, 6=í•˜ìœ„)
    'TREND_RATIO'           # ì—…ì¢… íŠ¸ë Œë“œ ì§€ìˆ˜(0~100)
]

# ---------------------- ê²½ë¡œ ìœ í‹¸ ----------------------
def get_paths():
    app_dir = Path(__file__).resolve().parent        # .../Bigcontest/App
    root_dir = app_dir.parent                        # .../Bigcontest
    model_dir = root_dir / "Model"
    logs_root = model_dir / "d3rlpy_logs"           # d3rlpyê°€ ìƒì„±í•˜ëŠ” ë£¨íŠ¸
    fixed_dir = logs_root / "DiscreteCQL"            # ê³ ì • í´ë”(ì•±ì´ ìš°ì„  ì½ìŒ)
    return {
        "ROOT": root_dir,
        "MODEL_DIR": model_dir,
        "LOGS_ROOT": logs_root,
        "FIXED_DIR": fixed_dir,
        "NODE_EMB": model_dir / "node_embeddings.csv",
    }

def assert_minimum_files(paths: dict):
    problems = []
    if not paths["NODE_EMB"].exists():
        problems.append(str(paths["NODE_EMB"]))
    def _has_d3(root: Path) -> bool:
        return any(root.rglob("model_*.d3")) if root.exists() else False
    if not (_has_d3(paths["FIXED_DIR"]) or _has_d3(paths["LOGS_ROOT"])):  # ì–´ëŠ í•œ ê³³ì—” ìˆì–´ì•¼ í•¨
        problems.append(f"{paths['LOGS_ROOT']}\\**\\model_*.d3 (ìµœì†Œ 1ê°œ)")
    if problems:
        raise FileNotFoundError("ë‹¤ìŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” ë¹„ì–´ ìˆìŒ):\n- " + "\n- ".join(problems))

# ------------------ ì²´í¬í¬ì¸íŠ¸ ë¡œë” -------------------
def _extract_step_num(p: Path) -> int:
    try:
        return int(p.stem.split("_")[-1])  # model_12345.d3 -> 12345
    except Exception:
        return -1

def _safe_build_from_params_json_v2(config_path: Path, device: str):
    obj = json.loads(config_path.read_text(encoding="utf-8"))

    # --- obs_dim / action_size íŒíŠ¸ ì¶”ì¶œ ---
    obs_shape = obj.get("observation_shape") or [21]
    if isinstance(obs_shape, list):
        obs_shape = tuple(obs_shape)
    elif not isinstance(obs_shape, tuple):
        obs_shape = (int(obs_shape),)
    obs_dim = int(obs_shape[0] if len(obs_shape) else 21)

    action_size_hint = int(
        obj.get("action_size")
        or obj.get("config", {}).get("action_size")
        or 4
    )

    # --- âœ… Config ìƒì„±: obj ì•ˆì— 'config'ê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì•„ë‹ˆë©´ json íŒŒì¼ ê²½ë¡œ(str)ë¡œ ---
    if "config" in obj and isinstance(obj["config"], dict):
        cfg = DiscreteCQLConfig.from_dict(obj["config"])
    else:
        cfg = DiscreteCQLConfig.from_json(str(config_path))

    algo = cfg.create(device=device)

    # âœ… ë”ë¯¸ Dataset (ì•¡ì…˜ íŒíŠ¸ë¥¼ 'ìµœëŒ€ê°’=action_size_hint-1'ë¡œ ì¤˜ì„œ action_sizeë¥¼ 4ë¡œ ì¡ê²Œ í•¨)
    dummy_obs  = np.zeros((1, obs_dim), dtype=np.float32)
    dummy_act  = np.array([max(0, action_size_hint - 1)], dtype=np.int64)  # â† ì—¬ê¸°!
    dummy_rew  = np.zeros((1,), dtype=np.float32)
    dummy_term = np.ones((1,), dtype=np.int64)

    dummy_ds = MDPDataset(
        observations=dummy_obs,
        actions=dummy_act,
        rewards=dummy_rew,
        terminals=dummy_term,
    )
    algo.build_with_dataset(dummy_ds)
    return algo, obs_dim, action_size_hint

def _scan_candidates(root: Path):
    """ì£¼ì–´ì§„ root ì•„ë˜ì˜ .d3 í›„ë³´ë“¤ì„ (step, mtime) ê¸°ì¤€ ìµœì‹  ìš°ì„  ì •ë ¬í•´ ë°˜í™˜. 100KB ì´ˆê³¼ë§Œ."""
    if not root.exists():
        return []
    cands = [p for p in root.rglob("model_*.d3") if p.stat().st_size > 100_000]
    cands = sorted(cands, key=lambda p: (_extract_step_num(p), p.stat().st_mtime), reverse=True)
    return cands

def load_discrete_cql_with_fallback(logs_root: Path, fixed_dir: Path, device: str):
    """
    1) ê³ ì • í´ë”(DiscreteCQL/)ì—ì„œ ë¨¼ì € ì‹œë„
    2) ê·¸ë˜ë„ ì•ˆ ë˜ë©´ logs_root(íƒ€ì„ìŠ¤íƒ¬í”„ í´ë” í¬í•¨)ì—ì„œ ì‹œë„
    - í•­ìƒ ê°™ì€ í´ë”ì˜ params.jsonìœ¼ë¡œ cfg ìƒì„± â†’ ë”ë¯¸ datasetìœ¼ë¡œ build â†’ .d3 ë¡œë”©
    - 100KB ì´í•˜ .d3ëŠ” ìŠ¤í‚µ
    """
    tried = []

    # 1) ê³ ì • í´ë” ìš°ì„ 
    cands = _scan_candidates(fixed_dir)
    if cands:
        for ckpt in cands:
            params = ckpt.parent / "params.json"
            if not params.exists():
                tried.append(f"{ckpt.name}: params.json ì—†ìŒ (fixed)")
                continue
            try:
                algo, _, _ = _safe_build_from_params_json_v2(params, device)
                algo.load_model(str(ckpt))
                return algo, f"loaded: {ckpt.name} @ {ckpt.parent.name}"
            except Exception as ex:
                tried.append(f"{ckpt.name} (fixed): {type(ex).__name__}: {ex}")

    # 2) íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì „ì²´ ìŠ¤ìº”
    cands = _scan_candidates(logs_root)
    if cands:
        for ckpt in cands:
            params = ckpt.parent / "params.json"
            if not params.exists():
                tried.append(f"{ckpt.name}: params.json ì—†ìŒ")
                continue
            try:
                algo, _, _ = _safe_build_from_params_json_v2(params, device)
                algo.load_model(str(ckpt))
                return algo, f"loaded: {ckpt.name} @ {ckpt.parent.name}"
            except Exception as ex:
                tried.append(f"{ckpt.name}: {type(ex).__name__}: {ex}")

    detail = "\n".join(tried) if tried else "(no candidates)"
    raise RuntimeError("ëª¨ë¸(.d3) ë¡œë”© ì‹¤íŒ¨.\n" + detail)

# ------------------ ì—ì´ì „íŠ¸ -------------------
class MarketQuantum:
    def __init__(self, logs_root: Path, fixed_dir: Path, node_data_path: Path):
        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
        self.model, self.source_info = load_discrete_cql_with_fallback(
            logs_root, fixed_dir, self.device
        )

        # ì„ë² ë”© ë¡œë“œ
        self.df_embeddings = pd.read_csv(node_data_path)

        # ì•¡ì…˜ ë¼ë²¨
        self.action_map = {
            0: "ì „ëµ 0 (í˜„ìƒ ìœ ì§€Â·ë‚´ë¶€ì—­ëŸ‰ ê°•í™”)",
            1: "ì „ëµ 1 (ì‹ ê·œ ê³ ê° ìœ ì¹˜ ì§‘ì¤‘: ì½˜í…ì¸ Â·SNSÂ·ì œíœ´)",
            2: "ì „ëµ 2 (ì¬ë°©ë¬¸Â·ë°°ë‹¬ ì§‘ì¤‘: ë©¤ë²„ì‹­Â·ë”œë¦¬ë²„ë¦¬ ìµœì í™”)",
            3: "ì „ëµ 3 (ê³µê²©ì  í™•ì¥: ì‹ ë©”ë‰´+ì‹ ê·œÂ·ë°°ë‹¬ ë™ì‹œ ë“œë¼ì´ë¸Œ)",
        }

        # ì ì¬ë²¡í„° ì»¬ëŸ¼ í™•ì¸
        self.latent_cols = [f'latent_{i}' for i in range(LATENT_DIM)]
        missing_latent = [c for c in self.latent_cols if c not in self.df_embeddings.columns]
        if missing_latent or 'ENCODED_MCT' not in self.df_embeddings.columns:
            need = missing_latent + (['ENCODED_MCT'] if 'ENCODED_MCT' not in self.df_embeddings.columns else [])
            raise ValueError(f"node_embeddings.csv ì»¬ëŸ¼ ëˆ„ë½: {need}")

        # âœ… í˜„ì¬ëŠ” ë¬´ìŠ¤ì¼€ì¼ ì¶”ë¡ (ì›ê°’). í•„ìš” ì‹œ ìŠ¤ì¼€ì¼ëŸ¬ ì ìš© ì½”ë“œë¡œ ì „í™˜ ê°€ëŠ¥.
        self._use_scaler = False

    def get_state_vector(self, mct_id, monthly_data):
        row = self.df_embeddings[self.df_embeddings['ENCODED_MCT'] == mct_id]
        if row.empty:
            return None
        latent_vector = row[self.latent_cols].values[0].astype(np.float32)

        monthly_df = pd.DataFrame([monthly_data], columns=FEATURES)
        if self._use_scaler:
            # TODO: ìŠ¤ì¼€ì¼ ì‚¬ìš© ì „í™˜ ì‹œ scaler ì ìš©
            raise RuntimeError("í˜„ì¬ ì„¤ì •ì€ ë¬´ìŠ¤ì¼€ì¼ ì¶”ë¡ ì…ë‹ˆë‹¤. ìŠ¤ì¼€ì¼ ì‚¬ìš© ì „í™˜ ì‹œ scaler ì ìš© ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        feat_vec = monthly_df.values.astype(np.float32).flatten()

        state_vector = np.concatenate([latent_vector, feat_vec]).astype(np.float32)
        return state_vector

    def recommend_strategy(self, state_vector):
        if state_vector is None:
            return "ë¶„ì„ ì‹¤íŒ¨: ê°€ê²Œ IDë¥¼ ì„ë² ë”©ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        # ê¸°ë³¸ argmax
        actions = self.model.predict(np.expand_dims(state_vector, axis=0))
        action_idx = int(actions[0])

        # ë™ì  íƒ€ì´ë¸Œë ˆì´í¬ (Qê°€ ë‚©ì‘í•  ë•Œ)
        try:
            q = self.model.predict_value(np.expand_dims(state_vector, axis=0))[0]
            best = float(np.max(q))
            ties = np.where(np.isclose(q, best, rtol=1e-5, atol=1e-6))[0].tolist()
            if len(ties) > 1:
                action_idx = int(random.choice(ties))
        except Exception:
            pass

        return self.action_map.get(action_idx, f"ì•Œ ìˆ˜ ì—†ìŒ(action={action_idx})")

def _sanity_check_schema(agent: MarketQuantum):
    try:
        obs_shape = agent.model.observation_shape  # (21,) ê¸°ëŒ€
        expected = LATENT_DIM + len(FEATURES)
        if obs_shape and obs_shape[0] != expected:
            st.error(f"ê´€ì¸¡ ì°¨ì› ë¶ˆì¼ì¹˜: ëª¨ë¸ {obs_shape[0]} vs í˜„ì¬ ì…ë ¥ {expected}")
    except Exception:
        pass

@st.cache_resource
def load_ai_agent():
    paths = get_paths()
    assert_minimum_files(paths)
    agent = MarketQuantum(
        logs_root=paths["LOGS_ROOT"],
        fixed_dir=paths["FIXED_DIR"],
        node_data_path=paths["NODE_EMB"],
    )
    _sanity_check_schema(agent)
    return agent

# ========================== UI ==========================
st.set_page_config(page_title="ë§ˆì¼“ í€€í…€ AI ì „ëµ ì‹œë®¬ë ˆì´í„°", layout="wide")

# 1) ì—ì´ì „íŠ¸ ë¡œë”©
try:
    agent = load_ai_agent()
    all_store_ids = agent.df_embeddings['ENCODED_MCT'].dropna().unique()
except Exception as e:
    st.error(f"AI ì—ì´ì „íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

# 2) ì œëª©/ì„¤ëª…
st.title("ğŸ“ˆ ë§ˆì¼“ í€€í…€: AI ì „ëµ ì‹œë®¬ë ˆì´í„°")
st.markdown("ì„±ë™êµ¬ ìƒê¶Œ ë””ì§€í„¸ íŠ¸ìœˆ ê¸°ë°˜ìœ¼ë¡œ ì í¬ë³„ **ë¯¸ë˜ ì„±ê³µ í™•ë¥ ì„ ë†’ì´ëŠ” ì „ëµ**ì„ ì œì•ˆí•©ë‹ˆë‹¤.")
st.caption(
    f"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'} / Policy: DiscreteCQL / {agent.source_info}"
)
st.divider()

# 3) ì‚¬ì´ë“œë°” ì…ë ¥
with st.sidebar:
    st.header("ğŸ” ì‹œë®¬ë ˆì´ì…˜ ì •ë³´ ì…ë ¥")
    target_store_id = st.selectbox(
        "ë¶„ì„í•  ê°€ê²Œ ID:",
        options=all_store_ids,
        index=0 if len(all_store_ids) else None
    )

    st.subheader("ê°€ì¥ ìµœê·¼ ì›” ì§€í‘œ ì…ë ¥")
    dlv_rat = st.slider("ë°°ë‹¬ ë§¤ì¶œ ë¹„ì¤‘ (%)", 0.0, 100.0, 10.5)
    reu_rat = st.slider("ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨ (%)", 0.0, 100.0, 30.2)
    new_rat = st.slider("ì‹ ê·œ ê³ ê° ë¹„ìœ¨ (%)", 0.0, 100.0, 15.8)
    saa_rank = st.select_slider("ë§¤ì¶œ ìˆœìœ„ êµ¬ê°„(1=ìƒìœ„)", options=[1, 2, 3, 4, 5, 6], value=4)
    trend_ratio = st.slider("í˜„ì¬ ì—…ì¢… íŠ¸ë Œë“œ ì§€ìˆ˜", 0.0, 100.0, 88.7)

    st.divider()
    run_button = st.button("AI ì „ëµ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

# 4) ê²°ê³¼
if run_button:
    latest_monthly_data = [dlv_rat, reu_rat, new_rat, saa_rank, trend_ratio]
    with st.spinner('AIê°€ ë””ì§€í„¸ íŠ¸ìœˆì—ì„œ ë°˜ì‚¬ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ íƒìƒ‰ ì¤‘...'):
        state_vec = agent.get_state_vector(target_store_id, latest_monthly_data)
        recommendation = agent.recommend_strategy(state_vec)

    st.header("ğŸ“„ AI ì „ëµ ì‹œë®¬ë ˆì´ì…˜ ë¦¬í¬íŠ¸", divider='rainbow')
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="ë¶„ì„ ëŒ€ìƒ ê°€ê²Œ ID", value=str(target_store_id))
    with col2:
        st.metric(label="ë””ë°”ì´ìŠ¤", value="CUDA" if torch.cuda.is_available() else "CPU")

    st.subheader("âœ… AI ìµœì¢… ì „ëµ ì œì–¸")
    st.success(f"**{recommendation}**")

    st.info(
        "ê·¼ê±°: VGAE ì ì¬ì„ë² ë”© + ìµœì‹  ì§€í‘œ(ë°°ë‹¬Â·ì¬ë°©ë¬¸Â·ì‹ ê·œÂ·ë§¤ì¶œìˆœìœ„Â·íŠ¸ë Œë“œ) â†’ "
        "ì˜¤í”„ë¼ì¸ RL(DiscreteCQL)ë¡œ **ë°˜ì‚¬ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ íƒìƒ‰í•´ ì¥ê¸° ë³´ìƒ ê¸°ì¤€ìœ¼ë¡œ ìµœì  ì „ëµì„ ë„ì¶œí•©ë‹ˆë‹¤.",
        icon="ğŸ’¡"
    )

    # --- Q-values ë””ë²„ê·¸ íŒ¨ë„ ---
    with st.expander("ë””ë²„ê·¸: Q-values / ì…ë ¥ ìƒíƒœ ì ê²€", expanded=False):
        if state_vec is None:
            st.write("ì„ë² ë”©ì—ì„œ í•´ë‹¹ ê°€ê²Œë¥¼ ì°¾ì§€ ëª»í•´ ìƒíƒœë²¡í„°ê°€ None ì…ë‹ˆë‹¤.")
        else:
            try:
                q_values = agent.model.predict_value(np.expand_dims(state_vec, axis=0))[0]
                spread = float(np.max(q_values) - np.min(q_values))
                st.write("ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸:", agent.source_info)
                st.write("Q-values:", [float(x) for x in q_values])
                st.write(
                    "state_vector ìš”ì•½:",
                    {
                        "dim": int(len(state_vec)),
                        "min": float(np.min(state_vec)),
                        "max": float(np.max(state_vec)),
                        "mean": float(np.mean(state_vec)),
                    }
                )
                if spread < 1e-3:
                    st.warning("ëª¨ë“  ì•¡ì…˜ì˜ Qê°’ì´ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤. "
                               "í›ˆë ¨/ì¶”ë¡  ì…ë ¥ ë¶„í¬ ë¶ˆì¼ì¹˜ ë˜ëŠ” ëª¨ë¸ ë¯¸í•™ìŠµ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"Q spread OK: {spread:.4f}")
            except Exception as ex:
                st.error(f"Q-values ê³„ì‚° ì‹¤íŒ¨: {type(ex).__name__}: {ex}")

# ì‚¬ìš© íŒ
# - í•™ìŠµ:   py -3.13 .\Model\train_cql.py
# - ê²°ê³¼:   Model/d3rlpy_logs/DiscreteCQL/  â† ì´ í´ë”ë¥¼ ìš°ì„  ì‚¬ìš©
# - ì‹¤í–‰:   py -3.13 .\App\run_simulation.py
