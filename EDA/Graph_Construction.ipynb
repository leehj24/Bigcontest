{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5bbc833",
   "metadata": {},
   "source": [
    "#### ìœ„ê²½ë„ë³€í™˜ ê·¸ë˜í”„ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddf6d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ì§€ì˜¤ì½”ë”© ì‹œì‘ ---\n",
      "âœ… Step 1: 'node_features.csv' ë¡œë”© ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "print(\"--- ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ì§€ì˜¤ì½”ë”© ì‹œì‘ ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ë…¸ë“œ íŠ¹ì§• ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ==============================================================================\n",
    "try:\n",
    "    df = pd.read_csv(\"node_features.csv\")\n",
    "    print(\"âœ… Step 1: 'node_features.csv' ë¡œë”© ì„±ê³µ!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ì˜¤ë¥˜: 'node_features.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d337fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: ì£¼ì†Œ -> ìœ„ê²½ë„ ë³€í™˜ ì‘ì—… ì‹œì‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4185/4185 [1:53:13<00:00,  1.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Step 2: ì§€ì˜¤ì½”ë”© ì‘ì—… ì™„ë£Œ!\n",
      "  - ì´ 4185ê°œ ì£¼ì†Œ ì¤‘ 4151ê°œ ë³€í™˜ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 2. ì§€ì˜¤ì½”ë”©ì„ í†µí•´ ì£¼ì†Œë¥¼ ìœ„ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜\n",
    "# ==============================================================================\n",
    "# Nominatim ì§€ì˜¤ì½”ë” ì´ˆê¸°í™” (ê³µê°œ ì„œë¹„ìŠ¤ì´ë¯€ë¡œ ì‚¬ìš© ì •ì±… ì¡´ì¤‘ í•„ìš”)\n",
    "geolocator = Nominatim(user_agent=\"MarketQuantum-Project\")\n",
    "\n",
    "# ìœ„ë„ì™€ ê²½ë„ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "print(\"\\n--- Step 2: ì£¼ì†Œ -> ìœ„ê²½ë„ ë³€í™˜ ì‘ì—… ì‹œì‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤) ---\")\n",
    "# tqdm: ì§„í–‰ ìƒíƒœë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "for address in tqdm(df['MCT_BSE_AR']):\n",
    "    try:\n",
    "        # ì§€ì˜¤ì½”ë”© ì‹¤í–‰\n",
    "        location = geolocator.geocode(address)\n",
    "        \n",
    "        if location:\n",
    "            latitudes.append(location.latitude)\n",
    "            longitudes.append(location.longitude)\n",
    "        else:\n",
    "            latitudes.append(np.nan) # ì£¼ì†Œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê²°ì¸¡ì¹˜(NaN) ì²˜ë¦¬\n",
    "            longitudes.append(np.nan)\n",
    "            \n",
    "        # ì¤‘ìš”: ê³µê°œ APIì˜ ê³¼ë„í•œ ì‚¬ìš©ì„ ë§‰ê¸° ìœ„í•´ ê° ìš”ì²­ ì‚¬ì´ì— 1ì´ˆì˜ ì§€ì—°ì„ ì¤ë‹ˆë‹¤.\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        latitudes.append(np.nan)\n",
    "        longitudes.append(np.nan)\n",
    "\n",
    "# ë³€í™˜ëœ ìœ„ê²½ë„ ì •ë³´ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€\n",
    "df['latitude'] = latitudes\n",
    "df['longitude'] = longitudes\n",
    "\n",
    "print(\"\\nâœ… Step 2: ì§€ì˜¤ì½”ë”© ì‘ì—… ì™„ë£Œ!\")\n",
    "print(f\"  - ì´ {len(df)}ê°œ ì£¼ì†Œ ì¤‘ {df['latitude'].notna().sum()}ê°œ ë³€í™˜ ì„±ê³µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c367e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ìœ„ê²½ë„ ë³€í™˜ ê²°ê³¼ (ìƒìœ„ 5ê°œ) ---\n",
      "  ENCODED_MCT            MCT_BSE_AR   latitude   longitude\n",
      "0  000F03E44A   ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ4ê°€ê¸¸ 9  37.545333  127.046493\n",
      "1  002816BA73    ì„œìš¸ ì„±ë™êµ¬ ì²­ê³„ì²œë¡œ10ë‚˜ê¸¸ 78  37.570230  127.035313\n",
      "2  003473B465     ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì„œìš¸ìˆ²ê¸¸ 55  37.547951  127.040910\n",
      "3  003AC99735  ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ìš©ë‹µì¤‘ì•™15ê¸¸ 12  37.564492  127.053856\n",
      "4  0041E4E5AE   ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ìš©ë‹µì¤‘ì•™15ê¸¸ 1  37.563956  127.052843\n",
      "\n",
      "--- ë³€í™˜ ì‹¤íŒ¨(ê²°ì¸¡ì¹˜) ê°œìˆ˜ ---\n",
      "latitude     34\n",
      "longitude    34\n",
      "dtype: int64\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ìœ„ê²½ë„ ì¢Œí‘œê°€ ì¶”ê°€ëœ ë°ì´í„°ê°€ 'nodes_with_coords.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
    "# ==============================================================================\n",
    "print(\"\\n--- ìœ„ê²½ë„ ë³€í™˜ ê²°ê³¼ (ìƒìœ„ 5ê°œ) ---\")\n",
    "print(df[['ENCODED_MCT', 'MCT_BSE_AR', 'latitude', 'longitude']].head())\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ê°œìˆ˜ í™•ì¸\n",
    "print(\"\\n--- ë³€í™˜ ì‹¤íŒ¨(ê²°ì¸¡ì¹˜) ê°œìˆ˜ ---\")\n",
    "print(df[['latitude', 'longitude']].isnull().sum())\n",
    "\n",
    "# ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìœ„ê²½ë„ ì¢Œí‘œê°€ ì¶”ê°€ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "output_path = \"nodes_with_coords.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ìœ„ê²½ë„ ì¢Œí‘œê°€ ì¶”ê°€ëœ ë°ì´í„°ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86726757",
   "metadata": {},
   "source": [
    "##### ì—£ì§€ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfad0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\lib\\site-packages (1.26.4)\n",
      "Collecting haversine\n",
      "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: haversine\n",
      "Successfully installed haversine-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy haversine tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b17f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'ì—£ì§€ ë¦¬ìŠ¤íŠ¸' ìƒì„±ì„ í†µí•œ ê·¸ë˜í”„ ì™„ì„± ì‹œì‘ ---\n",
      "âœ… Step 1: 'nodes_with_coords.csv' ë¡œë”© ì„±ê³µ!\n",
      "âœ… Step 2: ê²°ì¸¡ì¹˜ ì œê±° ì™„ë£Œ! ì´ 4151ê°œì˜ ê°€ê²Œë¡œ ê±°ë¦¬ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "--- Step 3: 100m ì´ë‚´ ê°€ê²Œë“¤ì„ ì—°ê²°í•˜ëŠ” ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8613325/8613325 [02:28<00:00, 58121.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Step 3: ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ! ì´ 72426ê°œì˜ ì—°ê²°(ì—£ì§€)ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "\n",
      "--- ìƒì„±ëœ ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒ˜í”Œ (ìƒìœ„ 5ê°œ) ---\n",
      "       source      target\n",
      "0  000F03E44A  01EBAA3D0F\n",
      "1  000F03E44A  02EECADFE6\n",
      "2  000F03E44A  1C4665B740\n",
      "3  000F03E44A  268A868E38\n",
      "4  000F03E44A  2791AFFA12\n",
      "\n",
      "ğŸ‰ ê·¸ë˜í”„ ì™„ì„±! AIê°€ í•™ìŠµí•  ì—£ì§€ ë¦¬ìŠ¤íŠ¸ê°€ './edge_list.csv' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"--- 'ì—£ì§€ ë¦¬ìŠ¤íŠ¸' ìƒì„±ì„ í†µí•œ ê·¸ë˜í”„ ì™„ì„± ì‹œì‘ ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ìœ„ê²½ë„ ì¢Œí‘œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ==============================================================================\n",
    "try:\n",
    "    # ì§€ì˜¤ì½”ë”©ì„ í†µí•´ ìœ„ê²½ë„ ì¢Œí‘œê°€ ì¶”ê°€ëœ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    df = pd.read_csv(\"./nodes_with_coords.csv\")\n",
    "    print(\"âœ… Step 1: 'nodes_with_coords.csv' ë¡œë”© ì„±ê³µ!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ì˜¤ë¥˜: 'nodes_with_coords.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ì—£ì§€(Edge) ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì •ì œ\n",
    "# ==============================================================================\n",
    "# ì§€ì˜¤ì½”ë”©ì— ì‹¤íŒ¨í•œ (ìœ„ê²½ë„ ê°’ì´ ì—†ëŠ”) ê°€ê²ŒëŠ” ê±°ë¦¬ ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì œì™¸í•©ë‹ˆë‹¤.\n",
    "df_clean = df.dropna(subset=['latitude', 'longitude']).reset_index(drop=True)\n",
    "print(f\"âœ… Step 2: ê²°ì¸¡ì¹˜ ì œê±° ì™„ë£Œ! ì´ {len(df_clean)}ê°œì˜ ê°€ê²Œë¡œ ê±°ë¦¬ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 'ì—£ì§€ ë¦¬ìŠ¤íŠ¸' ìƒì„±\n",
    "# ==============================================================================\n",
    "# ì—£ì§€(ì—°ê²°)ë¥¼ ì •ì˜í•  ê±°ë¦¬ ê¸°ì¤€ ì„¤ì • (ë‹¨ìœ„: ë¯¸í„°)\n",
    "# ì˜ˆ: 100m ì•ˆì— ìˆëŠ” ê°€ê²Œë“¤ì€ ì„œë¡œ 'ì¸ì ‘'í•´ìˆë‹¤ê³  ì •ì˜\n",
    "DISTANCE_THRESHOLD_METERS = 100\n",
    "\n",
    "# ì—°ê²°ëœ ê°€ê²Œ ìŒ(ì—£ì§€)ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "edge_list = []\n",
    "\n",
    "print(f\"\\n--- Step 3: {DISTANCE_THRESHOLD_METERS}m ì´ë‚´ ê°€ê²Œë“¤ì„ ì—°ê²°í•˜ëŠ” ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ---\")\n",
    "\n",
    "# combinationsëŠ” ëª¨ë“  ê°€ëŠ¥í•œ ê°€ê²Œ ìŒì„ ì¤‘ë³µ ì—†ì´ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. (ì˜ˆ: (A,B), (A,C), (B,C)...)\n",
    "# tqdmì„ ì´ìš©í•´ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "for i, j in tqdm(combinations(df_clean.index, 2), total=len(df_clean)*(len(df_clean)-1)//2):\n",
    "    \n",
    "    # ë‘ ê°€ê²Œì˜ ì¢Œí‘œ (ìœ„ë„, ê²½ë„)\n",
    "    coords_1 = (df_clean['latitude'][i], df_clean['longitude'][i])\n",
    "    coords_2 = (df_clean['latitude'][j], df_clean['longitude'][j])\n",
    "    \n",
    "    # haversine ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ ë‘ ê°€ê²Œ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ë¯¸í„°(m) ë‹¨ìœ„ë¡œ ê³„ì‚°\n",
    "    distance = haversine(coords_1, coords_2, unit=Unit.METERS)\n",
    "    \n",
    "    # ë§Œì•½ ê±°ë¦¬ê°€ ìš°ë¦¬ê°€ ì„¤ì •í•œ ê¸°ì¤€ë³´ë‹¤ ê°€ê¹ë‹¤ë©´,\n",
    "    if distance <= DISTANCE_THRESHOLD_METERS:\n",
    "        # ì—£ì§€ ë¦¬ìŠ¤íŠ¸ì— ë‘ ê°€ê²Œì˜ ê³ ìœ  IDë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        # (source: ì¶œë°œ ë…¸ë“œ, target: ë„ì°© ë…¸ë“œ)\n",
    "        edge_list.append((df_clean['ENCODED_MCT'][i], df_clean['ENCODED_MCT'][j]))\n",
    "\n",
    "print(f\"\\nâœ… Step 3: ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ! ì´ {len(edge_list)}ê°œì˜ ì—°ê²°(ì—£ì§€)ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
    "# ==============================================================================\n",
    "# ìƒì„±ëœ ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_edges = pd.DataFrame(edge_list, columns=['source', 'target'])\n",
    "\n",
    "print(\"\\n--- ìƒì„±ëœ ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒ˜í”Œ (ìƒìœ„ 5ê°œ) ---\")\n",
    "print(df_edges.head())\n",
    "\n",
    "# ë‹¤ìŒ ë‹¨ê³„ì¸ VGAE ëª¨ë¸ë§ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "output_path = \"./edge_list.csv\"\n",
    "df_edges.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nğŸ‰ ê·¸ë˜í”„ ì™„ì„±! AIê°€ í•™ìŠµí•  ì—£ì§€ ë¦¬ìŠ¤íŠ¸ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
